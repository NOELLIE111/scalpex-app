# План реализации кроссплатформенного трейдинг-приложения "ScalpEX"

## Концепция

Создание многофункционального кроссплатформенного приложения (Windows, Linux, macOS, Android) для полуавтоматического трейдинга. Приложение должно предоставлять удобный графический интерфейс, поддерживать несколько торговых пар и бирж, и иметь возможность интеграции с Telegram.

---

## Общие архитектурные задачи и риски

### ⚠️ Возможные сложности и их решение

Используем 
requirements-dev.txt 
И
requirements.txt

*   **Сложность: Управление конфигурацией и секретами.**
    *   **Проблема:** Хранение API-ключей и других секретов в коде может привести к их утечке.
    *   **Решение:** Использовать переменные окружения и файл `.env` (добавленный в `.gitignore`) для хранения секретов, считывая их в приложении через библиотеку `python-dotenv`.

*   **Принцип: Полностью асинхронная архитектура (Async-First).**
    *   **Проблема:** Блокирующие операции ввода-вывода (сетевые запросы, обращения к БД) в серверной части приводят к деградации производительности и неэффективному использованию ресурсов.
    *   **Решение:** **Весь код серверной части должен быть полностью асинхронным.** Использовать `asyncio` как основу. Все библиотеки для работы с сетью, базами данных, кэшем и другими внешними сервисами должны быть асинхронными (`httpx`, `asyncpg`, `redis-py`). Это позволит одному воркеру эффективно обрабатывать тысячи одновременных соединений и задач.

*   **Сложность: Масштабируемость и работа под высокой нагрузкой.**
    *   **Проблема:** Архитектура серверной части должна выдерживать нагрузку от тысяч одновременных пользователей, особенно при реализации тяжелых функций (бэктестинг, оптимизация).
    *   **Решение: Горизонтальное масштабирование.** Проектировать серверную часть как набор stateless-сервисов под управлением балансировщика нагрузки. Для баз данных использовать репликацию и шардирование по ID пользователя. Для кэша использовать Redis Cluster. Это позволит добавлять вычислительные мощности по мере роста пользовательской базы.

---
## Фаза 0: Проработка "Подводных камней" (Ключевые архитектурные риски)

Прежде чем написать первую строку кода, необходимо продумать неочевидные, но критически важные проблемы, которые могут возникнуть в сложной распределенной системе.

### 1. Гонка состояний (Race Conditions)
*   **Проблема:** WebSocket-сообщение об исполнении ордера может прийти раньше, чем HTTP-ответ о его создании будет обработан и записан в БД. В результате система получит сообщение о неизвестном ей ордере и проигнорирует его.
*   **Решение: Механизм "ожидающего ордера" (Pending Order).**
    1.  Сразу после отправки запроса на создание ордера и получения подтверждения (ACK), немедленно создавать в Redis временный ключ (`pending_order:<order_id>`), содержащий `deal_id`.
    2.  Обработчик WebSocket, получив сообщение для этого `order_id`, будет сначала проверять наличие этого ключа. Если его нет, он будет ждать 1-2 секунды перед обработкой.
    3.  Это гарантирует, что к моменту обработки WebSocket-сообщения система уже будет "знать" о контексте ордера.

### 2. "Зависшие" блокировки и идемпотентность
*   **Проблема:** Воркер захватывает распределенную блокировку в Redis (например, `lock:deal:<deal_id>`) и "умирает" из-за ошибки. Блокировка остается активной до истечения таймаута, и никто другой не сможет обработать эту сделку.
*   **Решение: Идемпотентные операции и "Сторожевые" задачи.**
    *   **Идемпотентность:** Все критические операции (например, финализация сделки) должны быть спроектированы так, чтобы их можно было безопасно выполнять несколько раз. Функция должна сначала проверять конечное состояние (например, "сделка уже в `completeorder`?") и, если оно достигнуто, просто завершать работу.
    *   **"Сторожевые" задачи:** Реализовать фоновый процесс, который периодически ищет "зависшие" ресурсы (сделки, которые не финализируются; ордера, которые не отменяются) и принудительно запускает для них идемпотентную функцию-обработчик.

### 3. Неконсистентность данных (Биржа vs. Локальная БД)
*   **Проблема:** Пользователь вручную отменяет ордер на сайте биржи. Бот в этот момент был на перезагрузке и пропустил WebSocket-сообщение. В итоге, в локальной БД ордер числится как активный, а на бирже его нет.
*   **Решение: Слой сверки (Reconciliation Layer).**
    *   Это должен быть отдельный фоновый процесс, который периодически (например, раз в 5-10 минут) проходит по *всем* активным ордерам в локальной БД и сверяет их статус с реальным статусом на бирже через HTTP API.
    *   При обнаружении расхождения он принудительно обновляет статус в локальной БД. Это "ремень безопасности", который ловит все, что пропустил WebSocket.

### 4. Обратная совместимость при обновлениях
*   **Проблема:** При выкатке новой версии кода, которая использует новый формат данных (например, в Redis), старые, еще не обновленные воркеры могут "упасть", столкнувшись с неизвестным форматом.
*   **Решение: Двухфазный деплой для изменений формата данных.**
    1.  **Фаза 1 (Переходная):** Развертывается версия кода, которая умеет **читать оба формата (старый и новый)**, но **пишет только в новом**.
    2.  **Фаза 2 (Миграция):** После того как все воркеры обновились до переходной версии, запускается скрипт, который конвертирует все оставшиеся данные в старом формате в новый.
    3.  **Фаза 3 (Финальная):** Развертывается финальная версия кода, которая работает **только с новым форматом**.

## Детализированная техническая архитектура для масштабирования

---

## Фаза 0.5: Организация процесса разработки (Команда и Инструменты)

Этот раздел описывает инструменты и практики для эффективной командной работы и решения специфичных проблем кроссплатформенной разработки.

### 1. Подводные камни кроссплатформенной разработки (ПК + Android)

*   **Проблема: Разный пользовательский опыт (UI/UX).**
    *   **Описание:** Интерфейс, удобный для мыши на большом экране, неюзабелен на маленьком сенсорном экране.
    *   **Решение:** Проектировать **адаптивные макеты**. Использовать `kivy.utils.platform` для определения платформы и подгрузки разных `.kv` файлов или динамического изменения виджетов.

*   **Проблема: Доступ к нативным API.**
    *   **Описание:** Отправка push-уведомлений, доступ к файловой системе, вибрация — всё это работает по-разному на Windows и Android.
    *   **Решение:** Использовать библиотеки-абстракции, в первую очередь **Plyer**, которая предоставляет единый Python API для доступа к нативным функциям.

*   **Проблема: Жизненный цикл мобильного приложения.**
    *   **Описание:** Android может "убить" приложение в любой момент для освобождения памяти.
    *   **Решение:** Корректно обрабатывать методы `on_pause` и `on_resume` в Kivy. В `on_pause` — можно корректно закрыть WebSocket-соединение с сервером. В `on_resume` — необходимо инициировать процесс переподключения к серверу и полной синхронизации состояния.

### 2. Инструменты для командной работы

*   **Проблема: Неконсистентность окружения ("У меня работает!").**
    *   **Описание:** Разные версии Python, библиотек, ОС у разработчиков приводят к трудновоспроизводимым багам.
    *   **Решение:** **Docker и Docker Compose.** Создается файл `docker-compose.yml`, описывающий всю среду (Python, PostgreSQL, Redis). Каждый разработчик одной командой (`docker-compose up`) запускает у себя полностью идентичное, изолированное окружение.

*   **Проблема: Хаос в кодовой базе и конфликты слияния.**
    *   **Описание:** Несколько разработчиков одновременно правят одни и те же файлы в одной ветке.
    *   **Решение:** **Система ветвления Git (например, GitFlow).**
        *   `main`: Только стабильный, протестированный код.
        *   `develop`: Основная ветка разработки.
        *   `feature/*`: Отдельная ветка для каждой задачи.
        *   Слияние в `develop` происходит только через **Pull/Merge Request** и **Code Review** (проверку кода другим членом команды).

*   **Проблема: Разный стиль кода и пропущенные ошибки.**
    *   **Описание:** Код становится трудночитаемым, в репозиторий попадают очевидные ошибки.
    *   **Решение: Автоматизация контроля качества.**
        *   **Pre-commit hooks:** Настройка хуков, которые перед каждым коммитом автоматически форматируют код (с помощью **Black**) и проверяют его на ошибки (с помощью **Ruff** / **Flake8**).
        *   **Continuous Integration (CI/CD):** Настройка (например, через **GitHub Actions**) для автоматического запуска тестов при каждом пуше в `develop` или создании Pull Request. Слияние блокируется, если тесты не прошли.

---

Этот раздел подробно описывает взаимодействие компонентов системы в распределенной среде, а также процессы масштабирования и обновления.

### 1. Декомпозиция на сервисы (Роли серверов)

Система разделяется на несколько типов независимых сервисов, каждый со своей зоной ответственности:

*   **API-сервер (Frontend Service):**
    *   **Назначение:** Единственная точка входа для всех клиентских приложений (GUI, Telegram). Обрабатывает HTTP-запросы, аутентификацию, валидацию данных.
    *   **Логика:** Не выполняет длительных операций. Его задача — принять запрос и положить задание в очередь в Redis.
    *   **Масштабирование:** Горизонтальное. Несколько экземпляров API-сервера размещаются за балансировщиком нагрузки (например, Nginx).

*   **Торговый воркер (Trade Worker):**
    *   **Назначение:** "Рабочая лошадка" системы. Выполняет всю основную бизнес-логику: подключается к WebSocket биржи, следит за ценами, исполняет ордера, рассчитывает прибыль.
    *   **Логика:** Является "stateless" (не хранит состояние). Забирает задачи из очередей Redis и записывает результат в общую базу данных. Не имеет прямого соединения с клиентом.
    *   **Масштабирование:** Горизонтальное. Количество воркеров можно увеличивать или уменьшать в зависимости от нагрузки (количества пользователей).

*   **Сервер Базы Данных (PostgreSQL):**
    *   **Назначение:** Централизованное, надежное хранилище данных ("источник правды"): пользователи, настройки, история сделок, статистика.
    *   **Масштабирование:** Вертикальное (увеличение мощности сервера) или через репликацию (создание read-only копий для снижения нагрузки на чтение).

*   **Сервер Redis:**
    *   **Назначение:** "Нервная система" и "краткосрочная память" всего приложения.
    *   **Роли:**
        1.  **Кэш:** Хранение часто запрашиваемых данных для снижения нагрузки на БД.
        2.  **Брокер сообщений:** Реализация очередей для асинхронного взаимодействия между API-сервером и воркерами.
        3.  **Координатор:** Управление состоянием воркеров (heartbeats, распределение пользователей) через атомарные операции.

### 2. Взаимодействие сервисов

Сервисы общаются друг с другом не напрямую, а через общие хранилища (БД и Redis), что обеспечивает их слабую связанность и отказоустойчивость.

*   **Пользователь -> API-сервер:** Прямой запрос (например, "изменить процент профита").
*   **API-сервер -> Redis:** Запись команды в очередь (например, `lpush queue:settings_change '{"user_id": 123, "profit": 1.5}'`).
*   **Redis -> Воркер:** Воркер постоянно слушает очередь и забирает задание (`rpop queue:settings_change`).
*   **Воркер -> БД:** Воркер выполняет логику и обновляет данные в PostgreSQL.
*   **БД/Redis -> API-сервер:** При следующем запросе от пользователя на отображение данных, API-сервер читает уже обновленную информацию из кэша Redis или напрямую из БД.

### 3. Процесс бесшовного обновления (Rolling Update)

Обновление приложения без остановки сервиса для пользователей.

1.  **Запуск новых воркеров:** Рядом с работающими воркерами версии `v1.0` запускаются новые воркеры с кодом `v1.1`. Они подключаются к тем же Redis и БД.
2.  **Плавная остановка старых воркеров:** Поочередно отправляется команда на завершение работы старым воркерам.
3.  **Освобождение пользователей:** Каждый старый воркер при выключении корректно завершает текущие операции и удаляет своих пользователей из общего пула `users:assigned` в Redis.
4.  **Автоматический подхват:** Новые воркеры `v1.1` в своем цикле перебалансировки обнаруживают освободившихся пользователей и немедленно берут их в работу.
5.  **Завершение:** Все старые воркеры остановлены, все пользователи без простоя переведены на новую версию кода.

**Ключевое требование:** Для такого обновления необходим инструмент миграции схемы БД (например, **Alembic**), чтобы гарантировать, что новая версия кода может работать со старой структурой БД на время переходного периода.

---

### 4. Архитектура для сверхвысоких нагрузок (10,000+ пользователей)

При переходе к десяткам и сотням тысяч пользователей требуется дальнейшее усиление архитектуры, особенно в части управления сетевым трафиком и хранения данных.

#### 4.1. Решение проблемы с белым списком IP: NAT Gateway

*   **Проблема:** API бирж часто требуют внесения IP-адресов серверов в белый список. При наличии десятков торговых воркеров на разных серверах управление этим списком становится невозможным.
*   **Решение:** Использование **NAT Gateway (Сетевого шлюза)**.
    *   **Принцип работы:** Все торговые воркеры размещаются в приватной сети. Весь их исходящий трафик в интернет (к API биржи) принудительно направляется через NAT Gateway, у которого есть один или несколько статических публичных IP-адресов.
    *   **Результат:** Для биржи все запросы от всех серверов приходят с одного и того же, заранее известного IP. В белый список на бирже нужно добавить только IP-адреса шлюзов (например, 2-3 для отказоустойчивости).

#### 4.2. Масштабирование баз данных и кэша

*   **База данных (PostgreSQL):**
    *   **Проблема:** Один сервер БД становится узким местом при большом количестве операций чтения (запрос статистики, истории сделок).
    *   **Решение:** **Репликация (Read Replicas).**
        *   **Master-сервер:** Обрабатывает все операции записи (`INSERT`, `UPDATE`).
        *   **Read Replica(s):** Несколько серверов-копий, которые обрабатывают все операции чтения (`SELECT`). Приложение настраивается так, чтобы направлять запросы на запись в Master, а запросы на чтение — распределять между репликами.

*   **Кэш и очереди (Redis):**
    *   **Проблема:** Один сервер Redis может не справиться с объемом данных и количеством операций.
    *   **Решение:** **Redis Cluster.** Встроенный режим Redis, который автоматически распределяет (шардирует) данные по нескольким узлам. Это обеспечивает как горизонтальное масштабирование производительности, так и высокую доступность.

#### 4.3. Общая схема взаимодействия при сверхвысоких нагрузках

```mermaid
graph TD
    subgraph "Клиенты"
        User_GUI[GUI Пользователя]
    end

    subgraph "Интернет"
        LB[Балансировщик нагрузки (Nginx / Cloud LB)]
        NAT[NAT Gateway (Статический IP)]
    end

    subgraph "Инфраструктура ScalpEX"
        API_Servers[API-серверы]
        Trade_Workers[Торговые воркеры]
        Redis_Cluster[Redis Cluster]
        PostgreSQL_Master[PostgreSQL Master (Запись)]
        PostgreSQL_Replicas[PostgreSQL Replicas (Чтение)]
    end

    User_GUI --> LB --> API_Servers
    API_Servers -- Задачи в очередь --> Redis_Cluster
    Trade_Workers -- Берут задачи из очереди --> Redis_Cluster
    Trade_Workers -- Запросы к бирже --> NAT --> Exchange[API Биржи]
    API_Servers -- Чтение данных --> PostgreSQL_Replicas
    Trade_Workers -- Запись данных --> PostgreSQL_Master
    API_Servers & Trade_Workers -- Кэш и координация --> Redis_Cluster
```

## Фаза 1: Разработка ядра и базовой логики (MVP)

**Цель:** Создать фундамент приложения, работающий из командной строки, реализующий всю бизнес-логику.

1.  **Архитектура:** Модульная структура, унифицированный интерфейс для коннекторов к биржам.
2.  **Торговый движок:** Поддержка нескольких пар, параллельные режимы (стандартный, реинвестирование).
3.  **Управление данными:** Проектирование БД (SQLite/PostgreSQL) и использование Redis для кэширования.
4.  **Режим реинвестирования:** Реализация пула средств, настроек в БД и сценариев использования.

### ⚠️ Возможные сложности и их решение (Фаза 1)

*   **Сложность: Ограничения API биржи (Rate Limits).**
    *   **Проблема:** Временная блокировка IP из-за превышения лимита запросов к бирже.
    *   **Решение:** Использовать **WebSockets** для данных в реальном времени и встроить в API-клиент механизм **Rate Limiter** для контроля частоты запросов.

*   **Сложность: Асинхронность и параллелизм.**
    *   **Проблема:** Приложение будет тормозить, если обрабатывать множество сетевых и вычислительных задач последовательно.
    *   **Решение:** **Строгое следование парадигме Async-First.** Ядро изначально строится на базе `asyncio`. Все операции ввода-вывода (HTTP-запросы к бирже, работа с PostgreSQL, взаимодействие с Redis) должны выполняться исключительно с использованием `await` и асинхронных библиотек.

*   **Сложность: Согласованность данных.**
    *   **Проблема:** Расхождение данных в локальной БД и на бирже в случае сбоя приложения.
    *   **Решение:** Реализовать **механизм сверки (reconciliation)**, который при запуске будет сравнивать и исправлять состояние ордеров.

---

## Фаза 2: Разработка графического интерфейса (GUI)

**Цель:** Создать удобный кроссплатформенный интерфейс для управления ядром.

1.  **Выбор технологии:** Основной фреймворк — **Kivy** для обеспечения работы на десктопе и Android из единой кодовой базы.
2.  **Основные экраны:** Дашборд, экран управления парой, настройки, история сделок.

### ⚠️ Возможные сложности и их решение (Фаза 2)

*   **Сложность: Производительность на мобильных устройствах.**
    *   **Проблема:** "Тормоза" и "зависания" интерфейса из-за ресурсоемкой логики трейдинга.
    *   **Решение (Клиент-Серверная архитектура):** Вся торговая логика выполняется на **удаленных серверах**. Клиентское приложение (GUI) является "тонким клиентом" или "пультом управления". Его задачи:
        1.  **Отправка команд:** Использовать **REST API** (HTTP-запросы) для отправки команд на сервер (например, `POST /api/trade/start`, `PUT /api/settings`). Это неблокирующие операции.
        2.  **Получение данных в реальном времени:** Использовать **WebSockets** для получения потока данных от сервера (обновление баланса, статуса сделок, логов). Это позволяет обновлять интерфейс без постоянных запросов.

*   **Сложность: Управление состоянием и соединением.**
    *   **Проблема:** Что делать, если мобильное приложение теряет связь с сервером? Как восстановить актуальное состояние после переподключения?
    *   **Решение:**
        1.  **Heartbeat-механизм:** Клиент и сервер должны периодически обмениваться "heartbeat" (пульс) сообщениями по WebSocket, чтобы обнаруживать обрывы связи.
        2.  **Логика переподключения:** В Kivy-приложении должна быть реализована автоматическая попытка восстановить WebSocket-соединение.
        3.  **Синхронизация состояния:** После успешного переподключения клиент должен запросить у сервера полный "снимок" текущего состояния (активные сделки, баланс), чтобы гарантировать консистентность отображаемых данных.

*   **Сложность: Сборка пакета для Android (.apk/.aab).**
    *   **Проблема:** Процесс упаковки Python-кода в мобильное приложение сложен и требует точной настройки.
    *   **Решение:** В самом начале проекта создать "Hello, World!" на Kivy и **собрать его для Android**, чтобы заранее отладить сборочное окружение (`buildozer`, Android SDK/NDK).

*   **Сложность: Адаптивный дизайн.**
    *   **Проблема:** Интерфейс должен корректно отображаться на экранах разного размера.
    *   **Решение:** Проектировать интерфейс с использованием адаптивных макетов (`Layouts`) и относительных единиц измерения.

---

## Фаза 3: Интеграция и расширение

**Цель:** Добавить дополнительные функции и улучшить взаимодействие с пользователем.

1.  **Интеграция с Telegram:** Уведомления и базовые команды.
2.  **Расширение функционала:** Поддержка новых бирж, аналитика, бэктестинг.

### ⚠️ Возможные сложности и их решение (Фаза 3)

*   **Сложность: Миграция базы данных.**
    *   **Проблема:** При добавлении новых функций потребуется изменять структуру БД, что может привести к потере данных у существующих пользователей.
    *   **Решение:** Использовать инструмент для миграций, например, **Alembic**, который позволяет версионно и безопасно обновлять схему базы данных.

---

## Фаза 4: Монетизация, Управление Пользователями и Поддержка

**Цель:** Превратить приложение в коммерческий продукт.

1.  **Система лицензирования и аутентификации:**
    *   **Задача:** Создать бэкенд-сервер (например, на FastAPI) для генерации, проверки и управления лицензионными ключами.
    *   **Реализация:** Клиентское приложение при запуске обращается к API сервера для валидации ключа.

2.  **Модель монетизации и интеграция с платежами:**
    *   **Задача:** Настроить прием платежей и автоматическую выдачу лицензий.
    *   **Реализация:** Интеграция бэкенд-сервера с платежным шлюзом (например, **Stripe**) для обработки подписок. Реализация тарифных планов (Trial, Standard, Pro) с разным уровнем доступа к функционалу.

3.  **Система автоматического обновления:**
    *   **Задача:** Упростить для пользователей процесс обновления приложения.
    *   **Реализация:** Встроить в клиентское приложение механизм, который при старте проверяет на сервере наличие новой версии и предлагает пользователю ее скачать и установить.

4.  **Сбор анонимной телеметрии:**
    *   **Задача:** Собрать данные для анализа использования продукта и планирования доработок.
    *   **Реализация:** Добавить опциональный (отключаемый) сбор анонимной статистики о том, какие функции используются чаще всего и где возникают ошибки.

---

## Перспективы развития и "Killer Features"

**Цель:** Превратить продукт из "хорошего" в "незаменимый", создав уникальные конкурентные преимущества.

1.  **"Умные" торговые функции:**
    *   **Paper Trading (Бумажная торговля):** Полноценный режим симуляции с виртуальным балансом для безопасного тестирования.
    *   **Бэктестинг стратегий:** Возможность проверить любую стратегию на исторических данных, чтобы оценить ее потенциальную прибыльность.
    *   **Оптимизатор стратегий:** Автоматический подбор наилучших параметров стратегии путем прогона сотен бэктестов.

2.  **Социальные и комьюнити-функции:**
    *   **Маркетплейс стратегий:** Платформа, где пользователи могут делиться (бесплатно или платно) своими конфигурациями стратегий.
    *   **Анонимные лидерборды:** Рейтинги самых прибыльных трейдеров для повышения вовлеченности и геймификации.

3.  **Повышенная безопасность и доверие:**
    *   **Двухфакторная аутентификация (2FA):** Для входа в личный кабинет управления подпиской.
    *   **Продвинутое локальное логирование:** Детальный, доступный пользователю журнал всех действий и решений бота для максимальной прозрачности.

---

## Фаза 5: Обеспечение качества и операционная надежность

**Цель:** Внедрить процессы и инструменты, которые гарантируют стабильность, надежность и высокое качество продукта в долгосрочной перспективе.

### 1. Комплексная стратегия тестирования

*   **Задача:** Автоматизировать проверку качества на всех уровнях, чтобы минимизировать регрессионные ошибки.
*   **Реализация:**
    *   **Unit-тесты (Pytest):** Покрытие тестами критически важной бизнес-логики (расчеты, обработка статусов, функции API-клиента). Запускаются на каждом коммите в CI.
    *   **Интеграционные тесты:** Тестирование взаимодействия сервисов в изолированном окружении (с использованием Docker Compose). Например, проверка полного цикла: "API-запрос -> Задание в Redis -> Обработка воркером -> Запись в БД".
    *   **End-to-End (E2E) тесты (Playwright/Selenium):** Автоматизированные сценарии, имитирующие действия пользователя в GUI и проверяющие корректность реакции всей системы.
    *   **Нагрузочные тесты (k6/JMeter):** Имитация высокой нагрузки на API-сервер и воркеры для выявления узких мест и проверки соответствия архитектуры заявленным требованиям по масштабированию.

### 2. Мониторинг, оповещения и централизованное логирование

*   **Задача:** Получать информацию о состоянии системы в реальном времени и узнавать о проблемах до того, как они затронут пользователей.
*   **Реализация:**
    *   **Сбор метрик (Prometheus):** Каждый сервис (API-сервер, воркер) предоставляет эндпоинт `/metrics` с ключевыми показателями: время ответа API, длина очередей в Redis, количество активных WebSocket-соединений, загрузка CPU/RAM.
    *   **Визуализация (Grafana):** Создание дашбордов для наглядного отображения "здоровья" системы.
    *   **Система оповещений (Alertmanager):** Настройка правил для критических метрик (например, "если среднее время обработки задачи в очереди > 30 секунд, отправить алерт").
    *   **Агрегация ошибок (Sentry):** Интеграция Sentry SDK во все компоненты для автоматического сбора и группировки всех необработанных исключений.
    *   **Централизованное логирование (ELK Stack / Loki):** Сбор логов со всех серверов и воркеров в единое хранилище для удобного поиска и анализа инцидентов.

### 3. Онбординг и поддержка пользователей

*   **Задача:** Упростить новым пользователям начало работы с продуктом и обеспечить эффективную обработку их обращений.
*   **Реализация:**
    *   **Интерактивный онбординг:** Встроенные в GUI подсказки и пошаговое руководство при первом запуске.
    *   **База знаний (Knowledge Base):** Создание публичного сайта с подробными инструкциями, статьями и видео-уроками (можно использовать такие платформы, как GitBook или MkDocs).
    *   **Система тикетов:** Интеграция с системой поддержки (например, Zendesk, Freshdesk или open-source аналогом), чтобы структурировать общение с пользователями и отслеживать статус решения проблем.
